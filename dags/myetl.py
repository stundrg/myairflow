from airflow import DAG
from airflow.operators.empty import EmptyOperator
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonVirtualenvOperator
import pendulum

# âœ… DAG ì„¤ì •
with DAG(
    "myetl",
    schedule="@hourly",
    start_date=pendulum.datetime(2025, 3, 13, tz="Asia/Seoul"),
    default_args={"depends_on_past": False},  # ğŸ”¥ ì‹¤í–‰ ì•ˆì •ì„± ì¶”ê°€
    max_active_runs=1,  # ğŸ”¥ ë™ì‹œì— ì—¬ëŸ¬ ê°œ ì‹¤í–‰ ë°©ì§€
) as dag:
    
    start = EmptyOperator(task_id="start")
    end = EmptyOperator(task_id="end")

    make_data = BashOperator(
        task_id="make_data",
        bash_command="""
            echo "make data"
            bash /home/wsl/airflow/make_data.sh /home/wsl/data/{{ data_interval_start.in_tz('Asia/Seoul').strftime('%Y/%m/%d/%H') }}
        """,
    )

    # âœ… CSV â†’ Parquet ë³€í™˜
    def run_load_data(input_path):
        """CSV ë°ì´í„°ë¥¼ Parquetìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
        from myetl.load_data import load_data  # ğŸ”¥ `sys.path.append(...)` ì œê±°
        output_path = input_path.replace("data.csv", "data.parquet")  # âœ… ìë™ìœ¼ë¡œ Parquet ê²½ë¡œ ì„¤ì •
        print(f"âœ… Load Data ì‹¤í–‰: {input_path} â†’ {output_path}")
        load_data(input_path, output_path)

    load_data = PythonVirtualenvOperator(
        task_id="load_data",
        python_callable=run_load_data,
        requirements=[
            "git+https://github.com/stundrg/myetl.git@0.1.0",  # ğŸ”¥ `0.1.0` ëŒ€ì‹  ìµœì‹  `main` ë²„ì „ ì‚¬ìš©
        ],
        system_site_packages=True,  # ğŸ”¥ ê¸°ì¡´ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
        op_args=["/home/wsl/data/{{ data_interval_start.in_tz('Asia/Seoul').strftime('%Y/%m/%d/%H') }}/data.csv"],  # âœ… CSV ê²½ë¡œ ì „ë‹¬
    )

    # âœ… Parquet â†’ Aggregation í›„ CSV ì €ì¥
    def run_agg_data(input_path):
        """Parquet ë°ì´í„°ë¥¼ Aggregation í›„ CSVë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
        from myetl.agg_data import agg_data  # ğŸ”¥ `sys.path.append(...)` ì œê±°
        output_path = input_path.replace("data.parquet", "agg.csv")  # âœ… ìë™ìœ¼ë¡œ Aggregation CSV ê²½ë¡œ ì„¤ì •
        print(f"âœ… Agg Data ì‹¤í–‰: {input_path} â†’ {output_path}")
        agg_data(input_path, output_path)

    agg_data = PythonVirtualenvOperator(
        task_id="agg_data",
        python_callable=run_agg_data,
        requirements=[
            "git+https://github.com/stundrg/myetl.git@0.1.0",  # ğŸ”¥ `0.1.0` ëŒ€ì‹  ìµœì‹  `main` ë²„ì „ ì‚¬ìš©
        ],
        system_site_packages=True,  # ğŸ”¥ ê¸°ì¡´ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
        op_args=["/home/wsl/data/{{ data_interval_start.in_tz('Asia/Seoul').strftime('%Y/%m/%d/%H') }}/data.parquet"],  # âœ… Parquet ê²½ë¡œ ì „ë‹¬
    )

    start >> make_data >> load_data >> agg_data >> end

if __name__ == "__main__":
    dag.test()
